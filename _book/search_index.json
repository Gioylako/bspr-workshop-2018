[
["index.html", "Data Science Workshop Overview Requirements", " Data Science Workshop British Society for Proteomic Research Meeting 2018 Alistair Bailey May 28 2018 Overview These lessons cover: An introduction to R and RStudio An introduction to the tidyverse Importing and transforming proteomics data Visualisation of proteomics analysis Requirements Up to date version of R and Rstudio The following R packages: install.packages(c(&quot;tidyverse&quot;,&quot;janitor&quot;)) "],
["intro.html", "Chapter 1 Introduction", " Chapter 1 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 1. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter ??. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 1.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 1.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2018) in this sample book, which was built on top of R Markdown and knitr (???). References "],
["the-tidyverse.html", "Chapter 2 The tidyverse", " Chapter 2 The tidyverse An introduction to the tidyverse. "],
["importing-and-transforming-proteomics-data.html", "Chapter 3 Importing and transforming proteomics data 3.1 Importing flat files 3.2 Calculating fold change and enrichment", " Chapter 3 Importing and transforming proteomics data 3.1 Importing flat files 3.2 Calculating fold change and enrichment 3.2.1 Fold change and log-fold change Fold changes are ratios, the ratio of say protein expression before and after treatment, where a value larger than 1 for a protein implies that protein expression was greater after the treatment. In life sciences, fold change is often reported as log-fold change. Why is that? There are at least two reasons which can be shown by plotting. One is that ratios are not symmetrical around 1, so it’s difficult to observe both changes in the forwards and backwards direcion i.e. proteins where expression went up and proteins where expression went down due to treatment. When we transform ratios on a log scale, the scale becomes symmetric around 0 and thus we can now observe the distribution of ratios in terms of positive, negative or no change. set.seed(10) x &lt;- 2^(rnorm(100)) y &lt;- 2^(rnorm(100)) ratios &lt;- tibble(value = x/y, label = &quot;ratios&quot;) logratios &lt;- tibble(value = log2(ratios$value), label = &quot;logratios&quot;) bind_rows(ratios,logratios) %&gt;% ggplot(aes(value)) + geom_histogram(binwidth = 2, colour = &quot;grey50&quot;, fill = &quot;white&quot;) + ggplot2::facet_wrap(~ label) + theme_minimal() A second reason is that transforming values onto a log scale changes where the numbers actually occur when plotted on that scale. If we consider the log scale to represent magnitudes, then we can more easily see changes of small and large magnitudes when we plot the data. For example, a fold change of 32 times can be either a ratio 1/32 or 32/1. 1/32 is much closer to 1 than 32/1, but transformed to a log scale we see that in terms of magnitude of difference it is the same as 32/1. x2 &lt;- 2^seq(1,5) y_vals &lt;- c(rev(1/x2),1,x2) names &lt;- c(paste0(&quot;1/&quot;,rev(x2)),1,x2) x_vals &lt;- seq(along=y_vals) dat &lt;- tibble(x_vals,y_vals,names) p1 &lt;- ggplot(dat,aes(x_vals,y_vals, label = names)) + geom_text() + geom_hline(yintercept = 1) + theme_minimal() + labs(x = NULL, y = NULL) + scale_x_continuous(breaks = NULL) p2 &lt;- ggplot(dat,aes(x_vals,y_vals, label = names)) + geom_text() + geom_hline(yintercept = 1) + scale_y_continuous(trans = &quot;log2&quot;) + theme_minimal() + labs(x = NULL, y = NULL) + scale_x_continuous(breaks = NULL) plot_grid(p1,p2) "],
["fold-change-and-t-test.html", "Chapter 4 Fold change and t-test", " Chapter 4 Fold change and t-test Load the data, we need multiple replicates for each condition. To be tidy each protein is a set of observations (rows) of the variables, which are the values recorded for each replicate (columns). ## Parsed with column specification: ## cols( ## protein.key_protein.Accession = col_character(), ## protein.Description = col_character(), ## `protein.ngramOnColumn -&gt; EmillyBowler_KOGSK_Rep1_001_Merged_Spectrum_IA_final_protein` = col_double(), ## `protein.ngramOnColumn -&gt; EmillyBowler_KOGSK_Rep2_Merged_IA_final_protein` = col_double(), ## `protein.ngramOnColumn -&gt; EmillyBowler_KOGSK_Rep3_001_Merged_Spectrum_IA_final_protein` = col_double(), ## `protein.ngramOnColumn -&gt; EmillyBowler_WT_Rep1_001_Merged_Spectrum_IA_final_protein` = col_double(), ## `protein.ngramOnColumn -&gt; EmillyBowler_WT_Rep2_001_Merged_Spectrum_IA_final_protein` = col_double(), ## `protein.ngramOnColumn -&gt; EmillyBowler_WT_Rep3_001_Merged_Spectrum_IA_final_protein` = col_double(), ## Present_NumFiles = col_integer() ## ) ## Observations: 6,150 ## Variables: 9 ## $ protein_key_protein_accession &lt;chr&gt; ... ## $ protein_description &lt;chr&gt; ... ## $ protein_ngram_on_column_emilly_bowler_kogsk_rep1_001_merged_spectrum_ia_final_protein &lt;dbl&gt; ... ## $ protein_ngram_on_column_emilly_bowler_kogsk_rep2_merged_ia_final_protein &lt;dbl&gt; ... ## $ protein_ngram_on_column_emilly_bowler_kogsk_rep3_001_merged_spectrum_ia_final_protein &lt;dbl&gt; ... ## $ protein_ngram_on_column_emilly_bowler_wt_rep1_001_merged_spectrum_ia_final_protein &lt;dbl&gt; ... ## $ protein_ngram_on_column_emilly_bowler_wt_rep2_001_merged_spectrum_ia_final_protein &lt;dbl&gt; ... ## $ protein_ngram_on_column_emilly_bowler_wt_rep3_001_merged_spectrum_ia_final_protein &lt;dbl&gt; ... ## $ present_num_files &lt;int&gt; ... Tidy up and deal with missing values, either impute or exclude missing values and normalise. Let’s consider our proteomics data as a distribution of values, one value for each protein in our experiment that together form a distribution. If we have replicate experiments we’ll therefore have multiple distributions. A quantile represents a region of distribution, for example the 0.95 quantile is the value such that 95% of the data lies below it. To normalise two or more distributions with each other without recourse to a reference distribution we: Rank (quantile) the value in each experiment (column) from lowest to highest. Sort each experiment (column) from lowest to highest value. Calculate the mean across the experiments (rows) on the sorted values. Substitute the mean values according to rank for each experiment to restore the original order. Dave Tang’s Blog : Quantile Normalisation in R .(???) Neither corresponds to the (???) implementation of quantile norm (est 2001 and explained below) pic.twitter.com/lCyy6YyNB8 — Rafael Irizarry ((???)) December 18, 2014 # Tidy data up dat_tidy &lt;- dat_em %&gt;% # Remove missing values drop_na() %&gt;% # Select and rename columns select(protein_accession = protein_key_protein_accession, protein_description, wt1 = protein_ngram_on_column_emilly_bowler_wt_rep1_001_merged_spectrum_ia_final_protein, wt2 = protein_ngram_on_column_emilly_bowler_wt_rep2_001_merged_spectrum_ia_final_protein, wt3 = protein_ngram_on_column_emilly_bowler_wt_rep3_001_merged_spectrum_ia_final_protein, kog1 = protein_ngram_on_column_emilly_bowler_kogsk_rep1_001_merged_spectrum_ia_final_protein, kog2 = protein_ngram_on_column_emilly_bowler_kogsk_rep2_merged_ia_final_protein, kog3 = protein_ngram_on_column_emilly_bowler_kogsk_rep3_001_merged_spectrum_ia_final_protein) # Plot data dat_tidy %&gt;% ggplot(aes(log2(wt1))) + geom_density() + geom_density(aes(log2(wt2), colour = &quot;blue&quot;)) + geom_density(aes(log2(wt3), colour = &quot;red&quot;)) # Normalise to maximum column value dat_norm_max &lt;- dat_tidy %&gt;% mutate(wt1 = wt1/max(wt1), wt2 = wt2/max(wt3), wt3 = wt3/max(wt3), kog1 = kog1 / max(kog1), kog2 = kog2 / max(kog2), kog3 = kog3 / max(kog3) ) # Normalise to median column value dat_norm_med &lt;- dat_tidy %&gt;% mutate(wt1 = wt1/median(wt1), wt2 = wt2/median(wt3), wt3 = wt3/median(wt3), kog1 = kog1 / median(kog1), kog2 = kog2 / median(kog2), kog3 = kog3 / median(kog3) ) dat_rank &lt;- dat_tidy %&gt;% select(-c(1:2,6:8)) %&gt;% apply(., 2, rank, ties.method=&quot;min&quot;) %&gt;% as.data.frame() dat_sort &lt;- dat_tidy %&gt;% select(-c(1:2,6:8)) %&gt;% apply(., 2, sort) %&gt;% as.data.frame() dat_mean &lt;- dat_sort %&gt;% apply(., 1, mean) index_mean &lt;- function(my_idx, my_mean){ return(my_mean[my_idx]) } dat_norm &lt;- dat_rank %&gt;% apply(.,2,index_mean, my_mean = dat_mean) %&gt;% as.data.frame() # dat_wt %&gt;% # ggplot(aes(log2(wt1))) + # geom_density() + # geom_density(aes(log2(wt2), colour = &quot;blue&quot;)) + # geom_density(aes(log2(wt3), colour = &quot;red&quot;)) # Quantile normalisation : the aim is to give different distributions the # same statistical properties quantile_normalisation &lt;- function(df){ # df_rank &lt;- apply(df,2,rank,ties.method=&quot;average&quot;) df_sorted &lt;- data.frame(apply(df, 2, sort)) df_mean &lt;- apply(df_sorted, 1, mean) index_to_mean &lt;- function(my_index, my_mean){ return(my_mean[my_index]) } df_final &lt;- apply(df_rank, 2, index_to_mean, my_mean=df_mean) %&gt;% as.data.frame() #rownames(df_final) &lt;- rownames(df) return(df_final) } dt_wt &lt;- dat_tidy %&gt;% select(-c(1:2,6:8)) dt_kog &lt;- dat_tidy %&gt;% select(-c(1:5)) dt_wt_norm &lt;- quantile_normalisation(dt_wt) dt_kog_norm &lt;- quantile_normalisation(dt_kog) dat_norm &lt;- bind_cols(dat_tidy[,1:2],dt_wt_norm,dt_kog_norm) # Have a look at the median normalised data glimpse(dat_norm_med) ## Observations: 1,095 ## Variables: 8 ## $ protein_accession &lt;chr&gt; &quot;4562_DHE3_HUMAN&quot;, &quot;14948_RS2_HUMAN&quot;, &quot;143... ## $ protein_description &lt;chr&gt; &quot;Glutamate dehydrogenase 1_ mitochondrial ... ## $ wt1 &lt;dbl&gt; 1.46455644, 3.78274902, 0.10257018, 1.5593... ## $ wt2 &lt;dbl&gt; 1.29015126, 3.06162560, 0.06677263, 1.2956... ## $ wt3 &lt;dbl&gt; 1.3898245, 4.6907618, 0.1136384, 0.7625680... ## $ kog1 &lt;dbl&gt; 2.1246421, 2.2498354, 0.2868330, 0.9172013... ## $ kog2 &lt;dbl&gt; 0.06248655, 3.78198563, 0.08551018, 0.5341... ## $ kog3 &lt;dbl&gt; 1.55811005, 2.16717459, 0.32849794, 0.8012... # Save the median normalised data write_excel_csv(dat_norm,&quot;data/example_median_nomralised_proteomics_data.csv&quot;) # Impute NA with lowest value, need to change this! control &lt;- dat_select %&gt;% filter(!is.na(control_1) | !is.na(control_2) | !is.na(control_3)) %&gt;% select(3,4,5) treatment &lt;- dat_select %&gt;% filter(!is.na(ras_1) | !is.na(ras_2) | !is.na(ras_3)) %&gt;% select(6,7,8) # Impute minimum row_min &lt;- function(x) apply(x,1,min,na.rm = TRUE) impute_min &lt;- function(x) replace(x, is.na(x), row_min(x)) #control_na &lt;- control %&gt;% filter(!complete.cases(.)) impute_min(control) control %&gt;% replace_na(apply(.,1,min)) Use t.test to perform Welch Two Sample t-test on untransformed data. This outputs the p-values we need for each protein. # T-test function for multiple experiments expriments_ttest &lt;- function(dt,grp1,grp2){ # Subset control group and convert to numeric x &lt;- dt[grp1] %&gt;% unlist %&gt;% as.numeric() # Subset treatment group and convert to numeric y &lt;- dt[grp2] %&gt;% unlist %&gt;% as.numeric() # Perform t-test result &lt;- t.test(x, y) # Return p-values return(result$p.value) } # Apply t-test function to data # array = dat, 1 = rows, FUN = expriments_ttest, and arguements # For median normalised data p_vals &lt;- apply(dat_norm,1,expriments_ttest, grp1 = c(3:5), grp2 = c(6:8)) # For maximum normalised data p_vals_max &lt;- apply(dat_norm_max,1,expriments_ttest, grp1 = c(3:5), grp2 = c(6:8)) # Plot histograms hist(p_vals) hist(p_vals_max) Perform log transformation of the observations for each protein. # Select columns and log data dat_log &lt;- dat_norm %&gt;% select(-c(protein_accession,protein_description)) %&gt;% log2() dat_max_log &lt;- dat_norm_max %&gt;% select(-c(protein_accession,protein_description)) %&gt;% log2() Calculate the mean observation for each protein under each condition. con &lt;- apply(dat_log[,1:3],1,mean) trt &lt;- apply(dat_log[,4:6],1,mean) con_max &lt;- apply(dat_max_log[,1:3],1,mean) trt_max &lt;- apply(dat_max_log[,4:6],1,mean) The log fold change is then the difference between condition 1 and condition 2. Plot a histogram to look at the distribution. # Calculate fold change dat_fc &lt;- con - trt dat_max_fc &lt;- con_max - trt_max # Plot histograms hist(dat_fc) hist(dat_max_fc) Create a combined table of log fold change and p-values for all the proteins for plotting a volcano plot. dat &lt;- data.frame(prots= dat_norm$protein_accession, logfc = dat_fc, pval = -1*log10(p_vals)) dat_max &lt;- data.frame(prots= dat_norm_max$protein_accession, logfc = dat_max_fc, pval = -1*log10(p_vals_max)) dat_max %&gt;% ggplot(aes(logfc,pval)) + geom_point() dat %&gt;% ggplot(aes(logfc,pval)) + geom_point() "],
["visualising-proteomics-data.html", "Chapter 5 Visualising proteomics data 5.1 Creating a volcano plot 5.2 Creating a heatmap", " Chapter 5 Visualising proteomics data Based on empircal research, there are some general rules on visulisations that are worth bearing in mind: Plot 5.1 Creating a volcano plot VOlcano plot is a plot of the log fold change in the observation between two conditions on the x-axis, for example the protein expression between treatment and control conditions. And on the y-axis is the corresponding p-value for each observation. The p-value representing the likelihood that an observed change is due to the different conditions rather than arising from natural variation in the fold change that might be observed if we performed many replications of the experiment. The aim of a volcano plot is to enable the viewer to quickly see the effect (if any) of an experiment with two conditions on many species i.e. proteins in terms of both increased and decreased expression. Like all plots it has it’s good and bad points, namely it’s good that we can visualise a lot of complex information in one plot. However this is also it’s main weakness, it’s rather complicated to understand in one glance. However, volcano plots are widely used in the literature, so there may be an amount of social proof giving rise to their popularity as opposed to their utility. 5.2 Creating a heatmap A "],
["going-further.html", "Chapter 6 Going further 6.1 Getting help and joining the R community 6.2 Communication: creating reports, presentations and websites", " Chapter 6 Going further 6.1 Getting help and joining the R community 6.2 Communication: creating reports, presentations and websites "],
["references.html", "References", " References "]
]
